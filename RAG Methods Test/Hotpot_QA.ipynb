{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question  \\\n",
      "1116  Out to Win is an American documentary film tha...   \n",
      "1368  Are both Variety and The Advocate LGBT-interes...   \n",
      "422   Who is this American rapper, songwriter, recor...   \n",
      "413   In which year was this American country music ...   \n",
      "451   What is the nationality of the actor who starr...   \n",
      "...                                                 ...   \n",
      "163   Kelly Jean Van Dyke is the niece of which Amer...   \n",
      "909   Which Superbowl featured Jack Maitland and was...   \n",
      "297   This American comedy-drama film directed by La...   \n",
      "755   Which city is north east of Normanby Island an...   \n",
      "405   Which headlined event did Romy Ruyssen face of...   \n",
      "\n",
      "                              answer        type  \n",
      "1116                 Houston Rockets      bridge  \n",
      "1368                              no  comparison  \n",
      "422                         Lil' Kim      bridge  \n",
      "413                             2000      bridge  \n",
      "451                         Scottish      bridge  \n",
      "...                              ...         ...  \n",
      "163           Richard Wayne Van Dyke      bridge  \n",
      "909                     Super Bowl V      bridge  \n",
      "297                 Shortland Street      bridge  \n",
      "755                           Cairns      bridge  \n",
      "405   Invicta Fighting Championships      bridge  \n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read HotpotQA results HyDE\n",
    "hotpotqa_df = pd.read_parquet('/Users/chengze/Desktop/hotpotqa_question_answer_type_200.parquet')\n",
    "print(hotpotqa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing evaluations: 100%|██████████| 200/200 [07:57<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              question  \\\n",
      "0    Out to Win is an American documentary film tha...   \n",
      "1    Are both Variety and The Advocate LGBT-interes...   \n",
      "2    Who is this American rapper, songwriter, recor...   \n",
      "3    In which year was this American country music ...   \n",
      "4    What is the nationality of the actor who starr...   \n",
      "..                                                 ...   \n",
      "195  Kelly Jean Van Dyke is the niece of which Amer...   \n",
      "196  Which Superbowl featured Jack Maitland and was...   \n",
      "197  This American comedy-drama film directed by La...   \n",
      "198  Which city is north east of Normanby Island an...   \n",
      "199  Which headlined event did Romy Ruyssen face of...   \n",
      "\n",
      "                                    retrieval_document  \\\n",
      "0    [(0.9446477, 'Sudanese-born Australian profess...   \n",
      "1    [(0.817297, 'ts and tourists on the right.  On...   \n",
      "2    [(0.95737755, 'response to Nicki Minaj\\'s song...   \n",
      "3    [(0.9063984, 'first tropical cyclone to make l...   \n",
      "4    [(0.84431934, 'ied 1968) was an English-Americ...   \n",
      "..                                                 ...   \n",
      "195  [(0.9413066, 'ial Science Research in Africa (...   \n",
      "196  [(0.9564918, 's graduated in 1878.  He was ord...   \n",
      "197  [(0.79559827, 'Sarah Fairbrother : Sarah Fairb...   \n",
      "198  [(0.931577, 'Joseph Moore (born July 25, 1958)...   \n",
      "199  [(1.0246497, 'ins at the \"Saturn Profi\" sports...   \n",
      "\n",
      "                                              response  processing_time  \\\n",
      "0    The retrieved context does not provide informa...         2.649622   \n",
      "1    Yes, both Variety and The Advocate are LGBT-in...         2.621281   \n",
      "2    The American rapper, songwriter, record produc...         2.265172   \n",
      "3    Trisha Yearwood, an American country music sin...         2.153594   \n",
      "4    The retrieved context does not provide informa...         1.867138   \n",
      "..                                                 ...              ...   \n",
      "195  Kelly Jean Van Dyke is the niece of American a...         5.978304   \n",
      "196  Super Bowl V featured Jack Maitland, who playe...         1.802630   \n",
      "197  The American comedy-drama film directed by Las...         2.609971   \n",
      "198  The retrieved context does not provide informa...         2.327917   \n",
      "199  I lack enough information to provide a definit...         2.973389   \n",
      "\n",
      "                             answer        type  \\\n",
      "0                   Houston Rockets      bridge   \n",
      "1                                no  comparison   \n",
      "2                          Lil' Kim      bridge   \n",
      "3                              2000      bridge   \n",
      "4                          Scottish      bridge   \n",
      "..                              ...         ...   \n",
      "195          Richard Wayne Van Dyke      bridge   \n",
      "196                    Super Bowl V      bridge   \n",
      "197                Shortland Street      bridge   \n",
      "198                          Cairns      bridge   \n",
      "199  Invicta Fighting Championships      bridge   \n",
      "\n",
      "                                       gpt4_evaluation  \n",
      "0    no\\nThe model generated answer does not align ...  \n",
      "1    no, the model generated answer contradicts the...  \n",
      "2    no\\n\\nThe ground truth answer is Lil' Kim, but...  \n",
      "3    Yes, the model-generated answer aligns with th...  \n",
      "4    no\\nThe model generated answer does not align ...  \n",
      "..                                                 ...  \n",
      "195  no\\nThe ground truth answer states that the pe...  \n",
      "196  Yes, the model-generated answer aligns with th...  \n",
      "197  Yes, the model-generated answer aligns with th...  \n",
      "198  no\\nThe model generated answer does not match ...  \n",
      "199  no\\nThe model-generated answer does not align ...  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "hotpotqa_df = pd.read_parquet('/Users/chengze/Desktop/HyDE_NaiveRAG_hotpotqa_response_results_answer_200.parquet')\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "def get_gpt4_response(answer, response):\n",
    "    try:\n",
    "        gpt_response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please evaluate if the response matches the reference answer.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Instructions\n",
    "You will receive a ground truth answer (referred to as Answer) and a model-generated answer (referred to as Response). Your task is to compare the two and determine whether they align.\n",
    "\n",
    "Note: The ground truth answer may sometimes be embedded within the model-generated answer. You need to carefully analyze and discern whether they align.\n",
    "Your Output:\n",
    "If the two answers align, respond with yes.\n",
    "If they do not align, respond with no.\n",
    "If you are very uncertain, respond with unclear.\n",
    "Your response should first include yes, no, or unclear, followed by an explanation.\n",
    "\n",
    "Example 1\n",
    "Answer: Houston Rockets\n",
    "Response: The basketball player who was drafted 18th overall in 2001 is Jason Collins, who was selected by the Houston Rockets.\n",
    "Expected output: yes\n",
    "\n",
    "Example 2\n",
    "Answer: no\n",
    "Response: Yes, both Variety and The Advocate are LGBT-interest magazines. The Advocate is explicitly identified as an American LGBT-interest magazine, while Variety, although primarily known for its coverage of the entertainment industry, also addresses topics relevant to the LGBT community.\n",
    "Expected output: no\n",
    "\n",
    "Input Data Format\n",
    "Ground Truth Answer: {answer}\n",
    "Model Generated Answer: {response}\n",
    "\n",
    "Expected Output\n",
    "yes, no, or unclear\n",
    "An explanation of your choice.\n",
    "\n",
    "Output:\"\"\"}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        return gpt_response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT-4 response: {e}\")\n",
    "        return str(e)\n",
    "\n",
    "for idx, row in tqdm(hotpotqa_df.iterrows(), total=len(hotpotqa_df), desc=\"Processing evaluations\"):\n",
    "    evaluation = get_gpt4_response(row['answer'], row['response'])\n",
    "    hotpotqa_df.at[idx, 'gpt4_evaluation'] = evaluation\n",
    "\n",
    "hotpotqa_df.to_parquet('/Users/chengze/Desktop/HyDE_NaiveRAG_hotpotqa_response_results_answer_200_updated.parquet')\n",
    "print(hotpotqa_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (percentage of correct answers): 61.50%\n",
      "\n",
      "Distribution of scores:\n",
      "binary_score\n",
      "1    123\n",
      "0     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert GPT-4 evaluations to binary scores\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('/Users/chengze/Desktop/HyDE_NaiveRAG_hotpotqa_response_results_answer_200_updated.parquet')\n",
    "df['binary_score'] = df['gpt4_evaluation'].apply(lambda x: 1 if x.lower().startswith('yes') else 0)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = df['binary_score'].mean()\n",
    "print(f\"\\nAccuracy (percentage of correct answers): {accuracy:.2%}\")\n",
    "\n",
    "# Display the distribution of scores\n",
    "print(\"\\nDistribution of scores:\")\n",
    "print(df['binary_score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded HotpotQA data: (200, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HotpotQA-HyDE: 100%|██████████| 200/200 [13:30<00:00,  4.05s/it]\n",
      "HotpotQA-GPT4-Eval: 100%|██████████| 200/200 [06:41<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STATS] Accuracy: 66.00% (132/200)\n",
      "[STATS] Average processing time: 2.92 seconds\n",
      "[INFO] Results saved to: /Users/chengze/Desktop/NaiveRAG_hotpotqa_response_results_200.parquet\n",
      "\n",
      "=== Final Data ===\n",
      "                                               question                answer  \\\n",
      "1116  Out to Win is an American documentary film tha...       Houston Rockets   \n",
      "1368  Are both Variety and The Advocate LGBT-interes...                    no   \n",
      "422   Who is this American rapper, songwriter, recor...              Lil' Kim   \n",
      "413   In which year was this American country music ...                  2000   \n",
      "451   What is the nationality of the actor who starr...              Scottish   \n",
      "861   Which tennis player is from the United States,...           James Arias   \n",
      "1063  When did the company that produced \"Six Gates ...               in 1986   \n",
      "741   Interval starred Merle Oberon who fell in love...                Laredo   \n",
      "1272  Which English Romantic poet wrote the sonnet t...  Percy Bysshe Shelley   \n",
      "259   In which stadium do the teams owned by Myra Kr...      Gillette Stadium   \n",
      "\n",
      "            type                                 retrieval_document  \\\n",
      "1116      bridge  [(0.94592315, 'Sudanese-born Australian profes...   \n",
      "1368  comparison  [(0.8172527, 'ts and tourists on the right.  O...   \n",
      "422       bridge  [(0.90227294, 'response to Nicki Minaj\\'s song...   \n",
      "413       bridge  [(0.90412176, 'first tropical cyclone to make ...   \n",
      "451       bridge  [(0.8274264, 'ied 1968) was an English-America...   \n",
      "861   comparison  [(0.90588176, 'erson shortlist; the winner was...   \n",
      "1063      bridge  [(1.0019454, 'East, Assam in the West and Mon ...   \n",
      "741       bridge  [(0.8616257, 'nd television actor.  The Hungar...   \n",
      "1272      bridge  [(0.8250584, 'Carrot soup : Carrot soup (refer...   \n",
      "259       bridge  [(0.9625947, 's graduated in 1878.  He was ord...   \n",
      "\n",
      "                                               response processing_time  \\\n",
      "1116  The documentary \"Out to Win\" focuses on key fi...        2.789476   \n",
      "1368  The Advocate is an American LGBT-interest maga...        6.501531   \n",
      "422   The American rapper, songwriter, record produc...        4.901564   \n",
      "413   Trisha Yearwood, the American country music si...        2.838064   \n",
      "451   The actor who starred as Rene Russo's husband ...        6.004711   \n",
      "861   Jimmy Arias is the tennis player from the Unit...         1.39334   \n",
      "1063  The company that produced \"Six Gates Far Away ...        5.578625   \n",
      "741   Interval starred Merle Oberon, who fell in lov...        3.057318   \n",
      "1272  The sonnet that inspired the character Ozymand...        2.810595   \n",
      "259   The teams owned by Myra Kraft's husband, Rober...        2.291953   \n",
      "\n",
      "                                        gpt4_evaluation  binary_score  \n",
      "1116  no, the model-generated answer does not mentio...             0  \n",
      "1368  yes, the model-generated answer aligns with th...             1  \n",
      "422   no\\n\\nThe ground truth answer is Lil' Kim, but...             0  \n",
      "413   Yes, the model-generated answer aligns with th...             1  \n",
      "451   no\\nThe model-generated answer does not provid...             0  \n",
      "861   Yes, the model-generated answer aligns with th...             1  \n",
      "1063  Yes, the model-generated answer aligns with th...             1  \n",
      "741   Yes, the model-generated answer aligns with th...             1  \n",
      "1272  Yes, the model-generated answer aligns with th...             1  \n",
      "259   Yes, the model-generated answer aligns with th...             1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from HyDE import HyDEConfig, Promptor, HyDE\n",
    "\n",
    "def get_gpt4_evaluation(ground_truth, model_response, openai_client):\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant. Please evaluate if the response matches the reference answer.\"\n",
    "    )\n",
    "    user_prompt = f\"\"\"Instructions\n",
    "You will receive a ground truth answer (referred to as Answer) and a model-generated answer (referred to as Response).\n",
    "Your task is to compare the two and determine whether they align.\n",
    "\n",
    "Note: The ground truth answer may sometimes be embedded within the model-generated answer.\n",
    "You need to carefully analyze and discern whether they align.\n",
    "\n",
    "Your Output:\n",
    "If the two answers align, respond with yes.\n",
    "If they do not align, respond with no.\n",
    "If you are very uncertain, respond with unclear.\n",
    "\n",
    "Your response should first include yes, no, or unclear, followed by an explanation.\n",
    "\n",
    "Example 1\n",
    "Answer: Houston Rockets\n",
    "Response: The basketball player who was drafted 18th overall in 2001 is Jason Collins, who was selected by the Houston Rockets.\n",
    "Expected output: yes\n",
    "\n",
    "Example 2\n",
    "Answer: no\n",
    "Response: Yes, both Variety and The Advocate are LGBT-interest magazines.\n",
    "          The Advocate is explicitly identified as an American LGBT-interest magazine,\n",
    "          while Variety, although primarily known for its coverage of the entertainment industry,\n",
    "          also addresses topics relevant to the LGBT community.\n",
    "Expected output: no\n",
    "\n",
    "Input Data Format\n",
    "Ground Truth Answer: {ground_truth}\n",
    "Model Generated Answer: {model_response}\n",
    "\n",
    "Expected Output\n",
    "yes, no, or unclear\n",
    "An explanation of your choice.\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        evaluation_text = completion.choices[0].message.content.strip()\n",
    "        return evaluation_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling GPT-4: {e}\")\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "\n",
    "def process_hotpotqa_questions(\n",
    "    input_parquet: str,\n",
    "    main_folder: str,\n",
    "    output_parquet: str = None,\n",
    "    openai_api_key: str = None\n",
    "):\n",
    "    openai_client = OpenAI(api_key=openai_api_key)\n",
    "    df = pd.read_parquet(input_parquet)\n",
    "    print(f\"[INFO] Loaded HotpotQA data: {df.shape}\")\n",
    "    with open('Hconfig.yaml', 'r', encoding='utf-8') as f:\n",
    "        base_config = yaml.safe_load(f)\n",
    "    base_config['config']['main_folder'] = main_folder\n",
    "    hyde_config = HyDEConfig(base_config)\n",
    "    promptor = Promptor(hyde_config)\n",
    "    hyde_obj = HyDE(hyde_config, promptor)\n",
    "\n",
    "    for col in [\"retrieval_document\", \"response\", \"processing_time\", \"gpt4_evaluation\", \"binary_score\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"HotpotQA-HyDE\"):\n",
    "        question = str(row['question'])\n",
    "        start_time = time.time()\n",
    "        retrieval_document = hyde_obj.e2e_search(question)\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "        if retrieval_document and isinstance(retrieval_document, list):\n",
    "            best_hit = [retrieval_document[0]]\n",
    "            response_data = hyde_obj.answer(best_hit, question)\n",
    "        else:\n",
    "            response_data = hyde_obj.answer([], question)\n",
    "\n",
    "        df.at[idx, \"retrieval_document\"] = str(retrieval_document)\n",
    "        df.at[idx, \"response\"] = response_data\n",
    "        df.at[idx, \"processing_time\"] = processing_time\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"HotpotQA-GPT4-Eval\"):\n",
    "        ground_truth = str(row['answer'])\n",
    "        model_resp = str(row['response'])\n",
    "        gpt_eval = get_gpt4_evaluation(\n",
    "            ground_truth=ground_truth,\n",
    "            model_response=model_resp,\n",
    "            openai_client=openai_client\n",
    "        )\n",
    "        df.at[idx, \"gpt4_evaluation\"] = gpt_eval\n",
    "\n",
    "    def to_binary_score(eval_str: str):\n",
    "        if not eval_str:\n",
    "            return 0\n",
    "        eval_str_lc = eval_str.strip().lower()\n",
    "        if eval_str_lc.startswith(\"yes\"):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df[\"binary_score\"] = df[\"gpt4_evaluation\"].apply(to_binary_score)\n",
    "    total_count = len(df)\n",
    "    num_correct = df[\"binary_score\"].sum()\n",
    "    accuracy = num_correct / total_count if total_count > 0 else 0.0\n",
    "    avg_processing_time = df[\"processing_time\"].mean() if total_count > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n[STATS] Accuracy: {accuracy:.2%} ({num_correct}/{total_count})\")\n",
    "    print(f\"[STATS] Average processing time: {avg_processing_time:.2f} seconds\")\n",
    "    if output_parquet:\n",
    "        df.to_parquet(output_parquet, index=False)\n",
    "        print(f\"[INFO] Results saved to: {output_parquet}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_parquet_path = \"/Users/chengze/Desktop/hotpotqa_question_answer_type_200.parquet\"\n",
    "    main_folder_path = \"/Users/chengze/Desktop/NaiveRAG_hotpotqa\"\n",
    "    output_parquet_path = \"/Users/chengze/Desktop/NaiveRAG_hotpotqa_response_results_200.parquet\"\n",
    "    openai_api_key = \"\"\n",
    "\n",
    "    df_result = process_hotpotqa_questions(\n",
    "        input_parquet=input_parquet_path,\n",
    "        main_folder=main_folder_path,\n",
    "        output_parquet=output_parquet_path,\n",
    "        openai_api_key=\"\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Final Data ===\")\n",
    "    print(df_result.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded HotpotQA data: (200, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_indexer_entities() got an unexpected keyword argument 'entity_embedding_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 312\u001b[0m\n\u001b[1;32m    304\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mrun(process_hotpotqa_questions_graphrag(\n\u001b[1;32m    305\u001b[0m         input_parquet\u001b[38;5;241m=\u001b[39minput_parquet,\n\u001b[1;32m    306\u001b[0m         hotpotqa_folder\u001b[38;5;241m=\u001b[39mhotpotqa_folder,\n\u001b[1;32m    307\u001b[0m         output_parquet\u001b[38;5;241m=\u001b[39moutput_parquet,\n\u001b[1;32m    308\u001b[0m         openai_api_key\u001b[38;5;241m=\u001b[39mopenai_api_key\n\u001b[1;32m    309\u001b[0m     ))\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 312\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 304\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m openai_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-VR5G8QNyygvboebq-0-rXSS-MxXzABKeLcnx6yy9MUT3BlbkFJDA9J_-UvQsQfT96y8EUmG7kkBtpNpNRI2sZECZQ1gA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# 以异步方式运行\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_hotpotqa_questions_graphrag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_parquet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_parquet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhotpotqa_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhotpotqa_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_parquet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_parquet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopenai_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_api_key\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tgrag/lib/python3.10/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tgrag/lib/python3.10/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tgrag/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tgrag/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[1], line 145\u001b[0m, in \u001b[0;36mprocess_hotpotqa_questions_graphrag\u001b[0;34m(input_parquet, hotpotqa_folder, output_parquet, openai_api_key)\u001b[0m\n\u001b[1;32m    138\u001b[0m text_unit_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTEXT_UNIT_TABLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# 如果有 entity_embedding_df、covariate_df，也可加载\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# 如: entity_embedding_df = pd.read_parquet(...)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m#    covariate_df = pd.read_parquet(...)\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# 调用 GraphRAG 提供的帮助函数\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m entities \u001b[38;5;241m=\u001b[39m \u001b[43mread_indexer_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_embedding_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m relationships \u001b[38;5;241m=\u001b[39m read_indexer_relationships(relationship_df)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# 如果有 covariates\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#   covariates_df = pd.read_parquet(...)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#   covariates = read_indexer_covariates(covariates_df)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# 否则\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_indexer_entities() got an unexpected keyword argument 'entity_embedding_df'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ======== GraphRAG 相关导入 ========\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.local_search.mixed_context import LocalSearchMixedContext\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore\n",
    "\n",
    "# ======== OpenAI GPT-4 相关 ========\n",
    "import openai\n",
    "\n",
    "# ======== HotpotQA Data + GPT-4 Evaluation ========\n",
    "\n",
    "def get_gpt4_evaluation(ground_truth: str, model_response: str) -> str:\n",
    "    \"\"\"\n",
    "    使用 GPT-4 对比 ground_truth 与 model_response\n",
    "    并给出 \"yes\", \"no\", 或 \"unclear\" + 解释 的评估结果。\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant. Please evaluate if the response matches the reference answer.\"\n",
    "    )\n",
    "    user_prompt = f\"\"\"Instructions\n",
    "You will receive a ground truth answer (referred to as Answer) and a model-generated answer (referred to as Response).\n",
    "Your task is to compare the two and determine whether they align.\n",
    "\n",
    "Note: The ground truth answer may sometimes be embedded within the model-generated answer.\n",
    "You need to carefully analyze and discern whether they align.\n",
    "\n",
    "Your Output:\n",
    "If the two answers align, respond with yes.\n",
    "If they do not align, respond with no.\n",
    "If you are very uncertain, respond with unclear.\n",
    "\n",
    "Your response should first include yes, no, or unclear, followed by an explanation.\n",
    "\n",
    "Example 1\n",
    "Answer: Houston Rockets\n",
    "Response: The basketball player who was drafted 18th overall in 2001 is Jason Collins, who was selected by the Houston Rockets.\n",
    "Expected output: yes\n",
    "\n",
    "Example 2\n",
    "Answer: no\n",
    "Response: Yes, both Variety and The Advocate are LGBT-interest magazines.\n",
    "          The Advocate is explicitly identified as an American LGBT-interest magazine,\n",
    "          while Variety, although primarily known for its coverage of the entertainment industry,\n",
    "          also addresses topics relevant to the LGBT community.\n",
    "Expected output: no\n",
    "\n",
    "Input Data Format\n",
    "Ground Truth Answer: {ground_truth}\n",
    "Model Generated Answer: {model_response}\n",
    "\n",
    "Expected Output\n",
    "yes, no, or unclear\n",
    "An explanation of your choice.\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # 调用 GPT-4 ChatCompletion\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        evaluation_text = completion.choices[0].message.content.strip()\n",
    "        return evaluation_text\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR calling GPT-4] {e}\")\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "\n",
    "async def process_hotpotqa_questions_graphrag(\n",
    "    input_parquet: str,\n",
    "    hotpotqa_folder: str,\n",
    "    output_parquet: str = None,\n",
    "    openai_api_key: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    使用 GraphRAG \"Local Search\" 对 hotpotqa_question_answer_type_200.parquet 的问题执行检索与回答，\n",
    "    然后用 GPT-4 做评估。\n",
    "    \n",
    "    :param input_parquet:  HotpotQA 的问题 + 答案数据集路径 (e.g. /Users/chengze/Desktop/hotpotqa_question_answer_type_200.parquet)\n",
    "    :param hotpotqa_folder: 包含 GraphRAG 索引产物 (entities, relationships, reports, text_units, etc.) 的文件夹路径\n",
    "                            (e.g. /Users/chengze/Desktop/HotpotQA)\n",
    "    :param output_parquet: 处理后的结果保存路径\n",
    "    :param openai_api_key: 你的 OpenAI API Key\n",
    "    \"\"\"\n",
    "    # ============= 1. 设置 OpenAI API Key =============\n",
    "    if openai_api_key:\n",
    "        openai.api_key = openai_api_key\n",
    "\n",
    "    # ============= 2. 读取 HotpotQA 数据集 =============\n",
    "    df = pd.read_parquet(input_parquet)\n",
    "    print(f\"[INFO] Loaded HotpotQA data: {df.shape}\")\n",
    "\n",
    "    # ============= 3. 加载 GraphRAG 索引产物 =============\n",
    "    # 假设您在 /Users/chengze/Desktop/HotpotQA/output 下有：\n",
    "    #   create_final_nodes.parquet, create_final_entities.parquet, create_final_relationships.parquet ...\n",
    "    #   create_final_text_units.parquet, create_final_community_reports.parquet\n",
    "    #   并且 lancedb/ 文件夹中有向量库\n",
    "    OUTPUT_DIR = os.path.join(hotpotqa_folder, \"output\")\n",
    "    LANCEDB_URI = os.path.join(OUTPUT_DIR, \"lancedb\")\n",
    "\n",
    "    ENTITY_TABLE = \"create_final_nodes\"           # or create_final_entities\n",
    "    RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "    COVARIATE_TABLE = \"create_final_covariates\"   # 如果您没有 covariates，可忽略\n",
    "    COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "    TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "\n",
    "    entity_df = pd.read_parquet(os.path.join(OUTPUT_DIR, f\"{ENTITY_TABLE}.parquet\"))\n",
    "    relationship_df = pd.read_parquet(os.path.join(OUTPUT_DIR, f\"{RELATIONSHIP_TABLE}.parquet\"))\n",
    "    report_df = pd.read_parquet(os.path.join(OUTPUT_DIR, f\"{COMMUNITY_REPORT_TABLE}.parquet\"))\n",
    "    text_unit_df = pd.read_parquet(os.path.join(OUTPUT_DIR, f\"{TEXT_UNIT_TABLE}.parquet\"))\n",
    "\n",
    "    # 如果有 entity_embedding_df、covariate_df，也可加载\n",
    "    # 如: entity_embedding_df = pd.read_parquet(...)\n",
    "    #    covariate_df = pd.read_parquet(...)\n",
    "\n",
    "    # 调用 GraphRAG 提供的帮助函数\n",
    "    entities = read_indexer_entities(entity_df, entity_embedding_df=None, level=2)\n",
    "    relationships = read_indexer_relationships(relationship_df)\n",
    "    # 如果有 covariates\n",
    "    #   covariates_df = pd.read_parquet(...)\n",
    "    #   covariates = read_indexer_covariates(covariates_df)\n",
    "    # 否则\n",
    "    covariates = None\n",
    "\n",
    "    reports = read_indexer_reports(report_df, entity_df, level=2)\n",
    "    text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "    # ============= 4. 连接向量数据库 (LanceDB) =============\n",
    "    description_embedding_store = LanceDBVectorStore(collection_name=\"default-entity-description\")\n",
    "    description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "\n",
    "    # ============= 5. 初始化 ChatOpenAI, Embedding, LocalSearchMixedContext =============\n",
    "    # 从环境变量或您自己的方式获取\n",
    "    graphrag_api_key = os.environ.get(\"GRAPHRAG_API_KEY\", openai_api_key or \"\")\n",
    "    graphrag_llm_model = os.environ.get(\"GRAPHRAG_LLM_MODEL\", \"gpt-4o-mini\")\n",
    "    graphrag_embedding_model = os.environ.get(\"GRAPHRAG_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=graphrag_api_key,\n",
    "        model=graphrag_llm_model,\n",
    "        api_type=OpenaiApiType.OpenAI,  # 也可能是 AzureOpenAI\n",
    "        max_retries=20,\n",
    "    )\n",
    "    token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    text_embedder = OpenAIEmbedding(\n",
    "        api_key=graphrag_api_key,\n",
    "        model=graphrag_embedding_model,\n",
    "        api_type=OpenaiApiType.OpenAI,\n",
    "        deployment_name=graphrag_embedding_model,\n",
    "        max_retries=20,\n",
    "    )\n",
    "\n",
    "    # 构建 context builder\n",
    "    context_builder = LocalSearchMixedContext(\n",
    "        community_reports=reports,\n",
    "        text_units=text_units,\n",
    "        entities=entities,\n",
    "        relationships=relationships,\n",
    "        covariates=covariates,  # 如果没有 covariates，这里是 None\n",
    "        entity_text_embeddings=description_embedding_store,\n",
    "        embedding_vectorstore_key=EntityVectorStoreKey.ID,  # 如果 vector store 使用 entity 标题作为主键，可改为 TITLE\n",
    "        text_embedder=text_embedder,\n",
    "        token_encoder=token_encoder,\n",
    "    )\n",
    "\n",
    "    local_context_params = {\n",
    "        \"text_unit_prop\": 0.5,\n",
    "        \"community_prop\": 0.1,\n",
    "        \"conversation_history_max_turns\": 5,\n",
    "        \"conversation_history_user_turns_only\": True,\n",
    "        \"top_k_mapped_entities\": 10,\n",
    "        \"top_k_relationships\": 10,\n",
    "        \"include_entity_rank\": True,\n",
    "        \"include_relationship_weight\": True,\n",
    "        \"include_community_rank\": False,\n",
    "        \"return_candidate_context\": False,\n",
    "        \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,\n",
    "        \"max_tokens\": 12000,\n",
    "    }\n",
    "\n",
    "    llm_params = {\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    search_engine = LocalSearch(\n",
    "        llm=llm,\n",
    "        context_builder=context_builder,\n",
    "        token_encoder=token_encoder,\n",
    "        llm_params=llm_params,\n",
    "        context_builder_params=local_context_params,\n",
    "        response_type=\"local search response\",  # 可根据需要调整\n",
    "    )\n",
    "\n",
    "    # ============= 6. 对 HotpotQA 中每条 \"question\" 执行检索 & 回答 + GPT-4 评价 =============\n",
    "    # 先为结果 DataFrame 添加所需列\n",
    "    for col in [\"retrieval_document\", \"response\", \"processing_time\", \"gpt4_evaluation\", \"binary_score\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"GraphRAG-LocalSearch\"):\n",
    "        question = str(row[\"question\"])\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 如果 GraphRAG 的 search_engine 只提供异步 asearch\n",
    "        # 这里需 await 调用\n",
    "        result = await search_engine.asearch(question)\n",
    "\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "        # result 的结构中包含 result.response 以及 result.context_data\n",
    "        # 视 GraphRAG 不同版本而异\n",
    "        retrieval_document = result.context_data.get(\"entities\", [])\n",
    "        # 也可以根据 context_data[\"sources\"] / context_data[\"relationships\"] 等做自定义拼接\n",
    "\n",
    "        response_data = result.response\n",
    "\n",
    "        # 回填\n",
    "        df.at[idx, \"retrieval_document\"] = str(retrieval_document)\n",
    "        df.at[idx, \"response\"] = response_data\n",
    "        df.at[idx, \"processing_time\"] = processing_time\n",
    "\n",
    "    # ============= 7. GPT-4 评价 =============\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"GPT4-Evaluation\"):\n",
    "        ground_truth = str(row[\"answer\"])\n",
    "        model_resp = str(row[\"response\"])\n",
    "        gpt_eval = get_gpt4_evaluation(ground_truth, model_resp)\n",
    "        df.at[idx, \"gpt4_evaluation\"] = gpt_eval\n",
    "\n",
    "    # ============= 8. 将 yes/no/unclear → 二元分数 =============\n",
    "    def to_binary_score(eval_str: str):\n",
    "        if not eval_str:\n",
    "            return 0\n",
    "        eval_str_lc = eval_str.strip().lower()\n",
    "        if eval_str_lc.startswith(\"yes\"):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df[\"binary_score\"] = df[\"gpt4_evaluation\"].apply(to_binary_score)\n",
    "\n",
    "    # ============= 9. 统计准确率 & 平均处理时长 =============\n",
    "    total_count = len(df)\n",
    "    num_correct = df[\"binary_score\"].sum()\n",
    "    accuracy = num_correct / total_count if total_count > 0 else 0.0\n",
    "    avg_processing_time = df[\"processing_time\"].mean() if total_count > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n[STATS] Accuracy: {accuracy:.2%} ({num_correct}/{total_count})\")\n",
    "    print(f\"[STATS] Average processing time: {avg_processing_time:.2f} seconds\")\n",
    "\n",
    "    # ============= 10. 保存到新的 parquet 文件 =============\n",
    "    if output_parquet:\n",
    "        df.to_parquet(output_parquet, index=False)\n",
    "        print(f\"[INFO] Results saved to: {output_parquet}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 假设您 HotpotQA folder 为 \"/Users/chengze/Desktop/HotpotQA\"\n",
    "    # 其中包含 output/ 文件夹存放 Graphrag 索引产物\n",
    "    hotpotqa_folder = \"/Users/chengze/Desktop/HotpotQA\"\n",
    "\n",
    "    # 输入数据集（问题 + 答案）\n",
    "    input_parquet = \"/Users/chengze/Desktop/hotpotqa_question_answer_type_200.parquet\"\n",
    "\n",
    "    # 输出结果文件\n",
    "    output_parquet = \"/Users/chengze/Desktop/GraphRAG_hotpotqa_response_results_200.parquet\"\n",
    "\n",
    "    # 设置您的 OpenAI Key\n",
    "    openai_api_key = \"\"\n",
    "\n",
    "    # 以异步方式运行\n",
    "    asyncio.run(process_hotpotqa_questions_graphrag(\n",
    "        input_parquet=input_parquet,\n",
    "        hotpotqa_folder=hotpotqa_folder,\n",
    "        output_parquet=output_parquet,\n",
    "        openai_api_key=openai_api_key\n",
    "    ))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_indexer_entities in module graphrag.query.indexer_adapters:\n",
      "\n",
      "read_indexer_entities(final_nodes: pandas.core.frame.DataFrame, final_entities: pandas.core.frame.DataFrame, community_level: int | None) -> list[graphrag.model.entity.Entity]\n",
      "    Read in the Entities from the raw indexing outputs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import graphrag.query.indexer_adapters as ia\n",
    "help(ia.read_indexer_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
