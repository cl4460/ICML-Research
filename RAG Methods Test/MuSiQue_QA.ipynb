{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             id  \\\n",
      "0           2hop__460946_294723   \n",
      "1           2hop__252311_366220   \n",
      "2           2hop__701895_752697   \n",
      "3           2hop__259228_793698   \n",
      "4           2hop__481349_302087   \n",
      "...                         ...   \n",
      "2412  3hop1__139787_88110_77129   \n",
      "2413  3hop2__101809_30152_20999   \n",
      "2414   3hop1__41865_55331_34700   \n",
      "2415  3hop2__30152_105395_20999   \n",
      "2416  3hop2__30152_107291_20999   \n",
      "\n",
      "                                               question  \\\n",
      "0             Who is the spouse of the Green performer?   \n",
      "1     Who founded the company that distributed the f...   \n",
      "2     What administrative territorial entity is the ...   \n",
      "3      Where is Ulrich Walter's employer headquartered?   \n",
      "4     Which company owns the manufacturer of Learjet...   \n",
      "...                                                 ...   \n",
      "2412  What was the first OS to support Hyper-V from ...   \n",
      "2413  How were those people defied by the use of new...   \n",
      "2414  Who sent naval ships to the body of water that...   \n",
      "2415  How were the people that the Somali Muslim Aju...   \n",
      "2416  How were the people that the Somali Muslim Aju...   \n",
      "\n",
      "                                 question_decomposition  \\\n",
      "0     [{'answer': 'Steve Hillage', 'id': 460946, 'pa...   \n",
      "1     [{'answer': 'Orion Pictures', 'id': 252311, 'p...   \n",
      "2     [{'answer': 'Nuevo Laredo', 'id': 701895, 'par...   \n",
      "3     [{'answer': 'German Aerospace Center', 'id': 2...   \n",
      "4     [{'answer': 'Bombardier Aerospace', 'id': 4813...   \n",
      "...                                                 ...   \n",
      "2412  [{'answer': 'MSNBC', 'id': 139787, 'paragraph_...   \n",
      "2413  [{'answer': 'Myanmar', 'id': 101809, 'paragrap...   \n",
      "2414  [{'answer': 'North Sea', 'id': 41865, 'paragra...   \n",
      "2415  [{'answer': 'the Portuguese', 'id': 30152, 'pa...   \n",
      "2416  [{'answer': 'the Portuguese', 'id': 30152, 'pa...   \n",
      "\n",
      "                                                 answer  \n",
      "0                                      Miquette Giraudy  \n",
      "1                                          Mike Medavoy  \n",
      "2                                            Tamaulipas  \n",
      "3                                               Cologne  \n",
      "4                                       Bombardier Inc.  \n",
      "...                                                 ...  \n",
      "2412                                          Windows 8  \n",
      "2413  The dynasty regrouped and defeated the Portuguese  \n",
      "2414                                             Caesar  \n",
      "2415  The dynasty regrouped and defeated the Portuguese  \n",
      "2416  The dynasty regrouped and defeated the Portuguese  \n",
      "\n",
      "[2417 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "musique_df = pd.read_parquet('/Users/chengze/Desktop/musique_ans_v1.0_dev.parquet')\n",
    "print(musique_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully sampled 175 samples and saved to 'musique_ans_v1.0_dev_175sample.parquet'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "musique_df = pd.read_parquet('/Users/chengze/Desktop/musique_ans_v1.0_dev.parquet')\n",
    "sample_df = musique_df.sample(n=175, random_state=42)\n",
    "sample_df.to_parquet('/Users/chengze/Desktop/musique_ans_v1.0_dev_175sample.parquet', index=False)\n",
    "\n",
    "print(\"Successfully sampled 175 samples and saved to 'musique_ans_v1.0_dev_175sample.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    id  \\\n",
      "0                  2hop__121145_561444   \n",
      "1                   2hop__86689_728109   \n",
      "2           3hop1__462960_160545_62931   \n",
      "3             3hop1__68732_39743_24526   \n",
      "4                  2hop__364489_861485   \n",
      "..                                 ...   \n",
      "170                2hop__580458_139390   \n",
      "171         3hop1__602329_792411_51423   \n",
      "172  4hop1__130480_53706_795904_580996   \n",
      "173                2hop__149710_108549   \n",
      "174                   2hop__283_574195   \n",
      "\n",
      "                                              question  \\\n",
      "0    Who did the creator of Derech Mitzvosecha follow?   \n",
      "1    What team drafted the winner of the NBA scorin...   \n",
      "2    Where was the film The Beach filmed in the cou...   \n",
      "3    What is the average winter daytime temperature...   \n",
      "4    Where is the location of the headquarters of t...   \n",
      "..                                                 ...   \n",
      "170  What was the cast member of The Bad Man nomina...   \n",
      "171  What is the name of the castle in the birth ci...   \n",
      "172  What shares a border with the city where someo...   \n",
      "173               Who is the show Hawkgirl is from by?   \n",
      "174  Where was the person who said she is the reign...   \n",
      "\n",
      "                                question_decomposition  \\\n",
      "0    [{'answer': 'Menachem Mendel Schneersohn', 'id...   \n",
      "1    [{'answer': 'James Harden', 'id': 86689, 'para...   \n",
      "2    [{'answer': 'Bangkok', 'id': 462960, 'paragrap...   \n",
      "3    [{'answer': 'Virginia', 'id': 68732, 'paragrap...   \n",
      "4    [{'answer': 'Minnesota Historical Society', 'i...   \n",
      "..                                                 ...   \n",
      "170  [{'answer': 'Walter Huston', 'id': 580458, 'pa...   \n",
      "171  [{'answer': 'Jane Siberry', 'id': 602329, 'par...   \n",
      "172  [{'answer': 'California', 'id': 130480, 'parag...   \n",
      "173  [{'answer': 'Smallville', 'id': 149710, 'parag...   \n",
      "174  [{'answer': 'Baz Luhrmann', 'id': 283, 'paragr...   \n",
      "\n",
      "                                      answer  \n",
      "0                            Dovber Schneuri  \n",
      "1                      Oklahoma City Thunder  \n",
      "2                         island Koh Phi Phi  \n",
      "3                     upper 40s–lower 50s °F  \n",
      "4                   Minnesota History Center  \n",
      "..                                       ...  \n",
      "170  Academy Award for Best Supporting Actor  \n",
      "171                                Casa Loma  \n",
      "172                                Rio Linda  \n",
      "173                             Alfred Gough  \n",
      "174       National Institute of Dramatic Art  \n",
      "\n",
      "[175 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read HotpotQA results HyDE\n",
    "musique_df = pd.read_parquet('/Users/chengze/Desktop/musique_ans_v1.0_dev_175sample.parquet')\n",
    "print(musique_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded MuSiQue data: (175, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MuSiQue-HyDE: 100%|██████████| 175/175 [13:13<00:00,  4.53s/it]\n",
      "MuSiQue-GPT4-Eval: 100%|██████████| 175/175 [06:08<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STATS] Accuracy: 9.14% (16/175)\n",
      "[STATS] Average processing time: 3.32 seconds\n",
      "[INFO] Results saved to: /Users/chengze/Desktop/NaiveRAG_musique_response_results_175sample.parquet\n",
      "\n",
      "=== Final Data ===\n",
      "                           id  \\\n",
      "0         2hop__121145_561444   \n",
      "1          2hop__86689_728109   \n",
      "2  3hop1__462960_160545_62931   \n",
      "3    3hop1__68732_39743_24526   \n",
      "4         2hop__364489_861485   \n",
      "5           2hop__835710_7298   \n",
      "6          2hop__96062_159673   \n",
      "7    3hop2__79512_16214_84681   \n",
      "8  3hop1__831499_228453_10972   \n",
      "9      3hop2__230_89048_66294   \n",
      "\n",
      "                                            question  \\\n",
      "0  Who did the creator of Derech Mitzvosecha follow?   \n",
      "1  What team drafted the winner of the NBA scorin...   \n",
      "2  Where was the film The Beach filmed in the cou...   \n",
      "3  What is the average winter daytime temperature...   \n",
      "4  Where is the location of the headquarters of t...   \n",
      "5  Along with the Closer performer, what notable ...   \n",
      "6  What other movie did the cast member of Escape...   \n",
      "7  When did the people who first imported slaves ...   \n",
      "8  When did the city where the headquarters of Ba...   \n",
      "9  Who played the singer of is She Really Going O...   \n",
      "\n",
      "                              question_decomposition  \\\n",
      "0  [{'answer': 'Menachem Mendel Schneersohn', 'id...   \n",
      "1  [{'answer': 'James Harden', 'id': 86689, 'para...   \n",
      "2  [{'answer': 'Bangkok', 'id': 462960, 'paragrap...   \n",
      "3  [{'answer': 'Virginia', 'id': 68732, 'paragrap...   \n",
      "4  [{'answer': 'Minnesota Historical Society', 'i...   \n",
      "5  [{'answer': 'Josh Groban', 'id': 835710, 'para...   \n",
      "6  [{'answer': 'Kurt Russell', 'id': 96062, 'para...   \n",
      "7  [{'answer': 'New Zealand', 'id': 79512, 'parag...   \n",
      "8  [{'answer': 'Sazerac Company', 'id': 831499, '...   \n",
      "9  [{'answer': 'Michael Jackson', 'id': 230, 'par...   \n",
      "\n",
      "                     answer  \\\n",
      "0           Dovber Schneuri   \n",
      "1     Oklahoma City Thunder   \n",
      "2        island Koh Phi Phi   \n",
      "3    upper 40s–lower 50s °F   \n",
      "4  Minnesota History Center   \n",
      "5             Michael Bublé   \n",
      "6         The Hateful Eight   \n",
      "7          13 December 1642   \n",
      "8                     1970s   \n",
      "9  Lawrence Hilton - Jacobs   \n",
      "\n",
      "                                  retrieval_document  \\\n",
      "0  [(0.99430287, 'ed 14 games, but had only start...   \n",
      "1  [(0.84796494, \"who is currently 18 years old a...   \n",
      "2  [(0.82500285, 'e nel pallone 2:L\\'allenatore n...   \n",
      "3  [(1.0308971, \"northern part of Norway. The isl...   \n",
      "4  [(0.9282622, 'hosts the production facilities ...   \n",
      "5  [(0.9888064, 'rom school for humming the Unite...   \n",
      "6  [(0.98066205, 'te television film based on the...   \n",
      "7  [(0.9742626, 'p II of Spain and his successors...   \n",
      "8  [(1.0158578, \"efferson County, Iowa, United St...   \n",
      "9  [(0.9506669, ', Germany. According to the band...   \n",
      "\n",
      "                                            response processing_time  \\\n",
      "0  The Retrieved Context does not provide any inf...        3.262522   \n",
      "1  I lack enough information to provide a definit...        2.310379   \n",
      "2  I lack enough information to provide a definit...         2.43613   \n",
      "3  I lack enough information to provide a definit...        2.187446   \n",
      "4  The headquarters of the publisher of \"Bamboo A...        1.449368   \n",
      "5  I lack enough information to provide a definit...        2.800155   \n",
      "6  I lack enough information to provide a definit...         3.33933   \n",
      "7  The Retrieved Context does not provide specifi...        7.630982   \n",
      "8  I lack enough information to provide a definit...         1.75622   \n",
      "9  The Retrieved Context does not provide enough ...        2.335948   \n",
      "\n",
      "                                     gpt4_evaluation  binary_score  \n",
      "0  no\\nThe model-generated answer does not align ...             0  \n",
      "1  no\\nThe model-generated answer does not align ...             0  \n",
      "2  no\\nThe model-generated answer does not mentio...             0  \n",
      "3  no\\nThe model-generated answer does not align ...             0  \n",
      "4  Yes, the model-generated answer aligns with th...             1  \n",
      "5  no\\nThe model-generated answer does not provid...             0  \n",
      "6  no\\n\\nThe ground truth answer indicates that a...             0  \n",
      "7  no\\n\\nThe ground truth answer indicates a spec...             0  \n",
      "8  no\\n\\nThe model-generated answer does not alig...             0  \n",
      "9  no\\nThe model-generated answer does not align ...             0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm  \n",
    "from openai import OpenAI\n",
    "from HyDE import HyDEConfig, Promptor, HyDE\n",
    "\n",
    "\n",
    "def get_gpt4_evaluation(ground_truth, model_response, openai_client):\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant. Please evaluate if the response matches the reference answer.\"\n",
    "    )\n",
    "    user_prompt = f\"\"\"Instructions\n",
    "You will receive a ground truth answer (referred to as Answer) and a model-generated answer (referred to as Response). \n",
    "Your task is to compare the two and determine whether they align.\n",
    "\n",
    "Note: The ground truth answer may sometimes be embedded within the model-generated answer. \n",
    "You need to carefully analyze and discern whether they align.\n",
    "\n",
    "Your Output:\n",
    "If the two answers align, respond with yes.\n",
    "If they do not align, respond with no.\n",
    "If you are very uncertain, respond with unclear.\n",
    "\n",
    "Your response should first include yes, no, or unclear, followed by an explanation.\n",
    "\n",
    "Example 1\n",
    "Answer: Houston Rockets\n",
    "Response: The basketball player who was drafted 18th overall in 2001 is Jason Collins, who was selected by the Houston Rockets.\n",
    "Expected output: yes\n",
    "\n",
    "Example 2\n",
    "Answer: no\n",
    "Response: Yes, both Variety and The Advocate are LGBT-interest magazines. \n",
    "          The Advocate is explicitly identified as an American LGBT-interest magazine, \n",
    "          while Variety, although primarily known for its coverage of the entertainment industry, \n",
    "          also addresses topics relevant to the LGBT community.\n",
    "Expected output: no\n",
    "\n",
    "Input Data Format\n",
    "Ground Truth Answer: {ground_truth}\n",
    "Model Generated Answer: {model_response}\n",
    "\n",
    "Expected Output\n",
    "yes, no, or unclear\n",
    "An explanation of your choice.\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        evaluation_text = completion.choices[0].message.content.strip()\n",
    "        return evaluation_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling GPT-4: {e}\")\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "def process_musique_questions(\n",
    "    input_parquet: str,\n",
    "    main_folder: str,\n",
    "    output_parquet: str = None,\n",
    "    openai_api_key: str = None\n",
    "):\n",
    "    \n",
    "    openai_client = OpenAI(api_key=openai_api_key)\n",
    "    df = pd.read_parquet(input_parquet)\n",
    "    print(f\"[INFO] Loaded MuSiQue data: {df.shape}\")\n",
    "\n",
    "    with open('Hconfig.yaml', 'r', encoding='utf-8') as f:\n",
    "        base_config = yaml.safe_load(f)\n",
    "    base_config['config']['main_folder'] = main_folder\n",
    "\n",
    "    hyde_config = HyDEConfig(base_config)\n",
    "    promptor = Promptor(hyde_config)\n",
    "    hyde_obj = HyDE(hyde_config, promptor)\n",
    "    for col in [\"retrieval_document\", \"response\", \"processing_time\", \"gpt4_evaluation\", \"binary_score\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"MuSiQue-HyDE\"):\n",
    "        question = str(row['question'])\n",
    "        start_time = time.time()\n",
    "        retrieval_document = hyde_obj.e2e_search(question)\n",
    "\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        if retrieval_document and isinstance(retrieval_document, list):\n",
    "            best_hit = [retrieval_document[0]]\n",
    "            response_data = hyde_obj.answer(best_hit, question)\n",
    "        else:\n",
    "            response_data = hyde_obj.answer([], question)\n",
    "\n",
    "        df.at[idx, \"retrieval_document\"] = str(retrieval_document)\n",
    "        df.at[idx, \"response\"] = response_data\n",
    "        df.at[idx, \"processing_time\"] = processing_time\n",
    "\n",
    "    # Use GPT-4 to compare the ground truth answer (df['answer']) with the HyDE response (df['response'])\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"MuSiQue-GPT4-Eval\"):\n",
    "        gpt_eval = get_gpt4_evaluation(\n",
    "            ground_truth=str(row['answer']),\n",
    "            model_response=str(row['response']),\n",
    "            openai_client=openai_client\n",
    "        )\n",
    "        df.at[idx, \"gpt4_evaluation\"] = gpt_eval\n",
    "\n",
    "\n",
    "    def to_binary_score(eval_str: str):\n",
    "        if not eval_str:\n",
    "            return 0\n",
    "        eval_str_lc = eval_str.strip().lower()\n",
    "        if eval_str_lc.startswith(\"yes\"):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df[\"binary_score\"] = df[\"gpt4_evaluation\"].apply(to_binary_score)\n",
    "    total_count = len(df)\n",
    "    num_correct = df[\"binary_score\"].sum()\n",
    "    accuracy = num_correct / total_count if total_count > 0 else 0.0\n",
    "    avg_processing_time = df[\"processing_time\"].mean() if total_count > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n[STATS] Accuracy: {accuracy:.2%} ({num_correct}/{total_count})\")\n",
    "    print(f\"[STATS] Average processing time: {avg_processing_time:.2f} seconds\")\n",
    "\n",
    "    if output_parquet:\n",
    "        df.to_parquet(output_parquet, index=False)\n",
    "        print(f\"[INFO] Results saved to: {output_parquet}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_parquet_path = \"/Users/chengze/Desktop/musique_ans_v1.0_dev_175sample.parquet\"  \n",
    "    main_folder_path = \"/Users/chengze/Desktop/NaiveRAG_musique\"             \n",
    "    output_parquet_path = \"/Users/chengze/Desktop/NaiveRAG_musique_response_results_175sample.parquet\"\n",
    "\n",
    "\n",
    "    df_result = process_musique_questions(\n",
    "        input_parquet=input_parquet_path,\n",
    "        main_folder=main_folder_path,\n",
    "        output_parquet=output_parquet_path,\n",
    "        openai_api_key= \"\"  \n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Final Data ===\")\n",
    "    print(df_result.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    id  \\\n",
      "0                  2hop__121145_561444   \n",
      "1                   2hop__86689_728109   \n",
      "2           3hop1__462960_160545_62931   \n",
      "3             3hop1__68732_39743_24526   \n",
      "4                  2hop__364489_861485   \n",
      "..                                 ...   \n",
      "170                2hop__580458_139390   \n",
      "171         3hop1__602329_792411_51423   \n",
      "172  4hop1__130480_53706_795904_580996   \n",
      "173                2hop__149710_108549   \n",
      "174                   2hop__283_574195   \n",
      "\n",
      "                                              question  \\\n",
      "0    Who did the creator of Derech Mitzvosecha follow?   \n",
      "1    What team drafted the winner of the NBA scorin...   \n",
      "2    Where was the film The Beach filmed in the cou...   \n",
      "3    What is the average winter daytime temperature...   \n",
      "4    Where is the location of the headquarters of t...   \n",
      "..                                                 ...   \n",
      "170  What was the cast member of The Bad Man nomina...   \n",
      "171  What is the name of the castle in the birth ci...   \n",
      "172  What shares a border with the city where someo...   \n",
      "173               Who is the show Hawkgirl is from by?   \n",
      "174  Where was the person who said she is the reign...   \n",
      "\n",
      "                                question_decomposition  \\\n",
      "0    [{'answer': 'Menachem Mendel Schneersohn', 'id...   \n",
      "1    [{'answer': 'James Harden', 'id': 86689, 'para...   \n",
      "2    [{'answer': 'Bangkok', 'id': 462960, 'paragrap...   \n",
      "3    [{'answer': 'Virginia', 'id': 68732, 'paragrap...   \n",
      "4    [{'answer': 'Minnesota Historical Society', 'i...   \n",
      "..                                                 ...   \n",
      "170  [{'answer': 'Walter Huston', 'id': 580458, 'pa...   \n",
      "171  [{'answer': 'Jane Siberry', 'id': 602329, 'par...   \n",
      "172  [{'answer': 'California', 'id': 130480, 'parag...   \n",
      "173  [{'answer': 'Smallville', 'id': 149710, 'parag...   \n",
      "174  [{'answer': 'Baz Luhrmann', 'id': 283, 'paragr...   \n",
      "\n",
      "                                      answer  \\\n",
      "0                            Dovber Schneuri   \n",
      "1                      Oklahoma City Thunder   \n",
      "2                         island Koh Phi Phi   \n",
      "3                     upper 40s–lower 50s °F   \n",
      "4                   Minnesota History Center   \n",
      "..                                       ...   \n",
      "170  Academy Award for Best Supporting Actor   \n",
      "171                                Casa Loma   \n",
      "172                                Rio Linda   \n",
      "173                             Alfred Gough   \n",
      "174       National Institute of Dramatic Art   \n",
      "\n",
      "                                    retrieval_document  \\\n",
      "0    [(0.99430287, 'ed 14 games, but had only start...   \n",
      "1    [(0.84796494, \"who is currently 18 years old a...   \n",
      "2    [(0.82500285, 'e nel pallone 2:L\\'allenatore n...   \n",
      "3    [(1.0308971, \"northern part of Norway. The isl...   \n",
      "4    [(0.9282622, 'hosts the production facilities ...   \n",
      "..                                                 ...   \n",
      "170  [(0.9261764, 'nated for Best Film Editing, and...   \n",
      "171  [(0.9993725, '903 – April 5, 1977) was the Pre...   \n",
      "172  [(0.93653417, \"of the hastily carried - out pr...   \n",
      "173  [(1.0228809, 'odes before Doherty joined the s...   \n",
      "174  [(1.0604708, '陳影雯), is a beauty pageant queen ...   \n",
      "\n",
      "                                              response  processing_time  \\\n",
      "0    The Retrieved Context does not provide any inf...         3.262522   \n",
      "1    I lack enough information to provide a definit...         2.310379   \n",
      "2    I lack enough information to provide a definit...         2.436130   \n",
      "3    I lack enough information to provide a definit...         2.187446   \n",
      "4    The headquarters of the publisher of \"Bamboo A...         1.449368   \n",
      "..                                                 ...              ...   \n",
      "170  The Retrieved Context does not provide any inf...         2.628629   \n",
      "171  The retrieved context does not provide informa...         2.260915   \n",
      "172  The retrieved context does not provide specifi...         3.822683   \n",
      "173  Hawkgirl is a character from the DC Universe a...         2.024775   \n",
      "174  The retrieved context does not provide informa...         2.227797   \n",
      "\n",
      "                                       gpt4_evaluation  binary_score  \n",
      "0    no\\nThe model-generated answer does not align ...             0  \n",
      "1    no\\nThe model-generated answer does not align ...             0  \n",
      "2    no\\nThe model-generated answer does not mentio...             0  \n",
      "3    no\\nThe model-generated answer does not align ...             0  \n",
      "4    Yes, the model-generated answer aligns with th...             1  \n",
      "..                                                 ...           ...  \n",
      "170  no, the model generated answer does not mentio...             0  \n",
      "171  no, the model generated answer does not align ...             0  \n",
      "172  no\\nThe model-generated answer does not mentio...             0  \n",
      "173  no\\nThe model-generated answer discusses the c...             0  \n",
      "174  no\\n\\nThe model-generated answer does not alig...             0  \n",
      "\n",
      "[175 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "musique_df = pd.read_parquet('/Users/chengze/Desktop/NaiveRAG_musique_response_results_175sample.parquet')\n",
    "print(musique_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
